{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WyV5_gdIzXbo"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "import copy\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import make_grid\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#globals\n",
        "def fix_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "seed = 0\n",
        "fix_seed(seed)\n",
        "\n",
        "num_clients = 10\n",
        "num_rounds = 5\n",
        "batch_size = 64\n",
        "lr = 0.01\n",
        "criterion = F.nll_loss\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "xlQpSEOLzryQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#utils\n",
        "\n",
        "#dataloader utils\n",
        "class NumpyDataset(Dataset):\n",
        "    \"\"\"This class allows you to convert numpy.array to torch.Dataset\"\"\"\n",
        "\n",
        "    def __init__(self, x, y=None, transform=None, return_idx=False):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.transform = transform\n",
        "        self.return_idx = return_idx\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.x[index]\n",
        "        if self.y is not None:\n",
        "            y = self.y[index]\n",
        "\n",
        "        if self.transform is not None:\n",
        "            x = self.transform(x)\n",
        "\n",
        "        if not self.return_idx:\n",
        "            if self.y is not None:\n",
        "                return x, y\n",
        "            else:\n",
        "                return x\n",
        "        else:\n",
        "            if self.y is not None:\n",
        "                return index, x, y\n",
        "            else:\n",
        "                return index, x\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"get the number of rows of self.x\"\"\"\n",
        "        return len(self.x)\n",
        "\n",
        "#client utils\n",
        "def default_local_train_for_client(self, local_epoch, criterion, trainloader, optimizer):\n",
        "    running_loss = 0.0\n",
        "    for _ in range(local_epoch):\n",
        "        for data in trainloader:\n",
        "            _, x, y = data\n",
        "            x = x.to(self.device)\n",
        "            y = y.to(self.device).to(torch.int64)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(self(x), y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "    return running_loss\n",
        "\n",
        "class RoundDecimal(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input, n_digits):\n",
        "        ctx.save_for_backward(input)\n",
        "        ctx.n_digits = n_digits\n",
        "        return torch.round(input * 10**n_digits) / (10**n_digits)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        grad_input = grad_output.clone()\n",
        "        return torch.round(grad_input * 10**ctx.n_digits) / (10**ctx.n_digits), None\n",
        "\n",
        "torch_round_x_decimal = RoundDecimal.apply\n",
        "\n",
        "def initialize_global_logit(len_public_dataloader, output_dim, device):\n",
        "    return torch.ones((len_public_dataloader, output_dim)).to(device) * float(\"inf\")\n",
        "\n",
        "#FedMD utils\n",
        "def accuracy_torch_dataloader(model, dataloader, device=\"cpu\", xpos=1, ypos=2):\n",
        "    \"\"\"Calculates the accuracy of the model on the given dataloader\n",
        "    Args:\n",
        "        model (torch.nn.Module): model to be evaluated\n",
        "        dataloader (torch.DataLoader): dataloader to be evaluated\n",
        "        device (str, optional): device type. Defaults to \"cpu\".\n",
        "        xpos (int, optional): the positional index of the input in data. Defaults to 1.\n",
        "        ypos (int, optional): the positional index of the label in data. Defaults to 2.\n",
        "    Returns:\n",
        "        float: accuracy\n",
        "    \"\"\"\n",
        "    in_preds = []\n",
        "    in_label = []\n",
        "    with torch.no_grad():\n",
        "        for data in dataloader:\n",
        "            inputs = data[xpos]\n",
        "            labels = data[ypos]\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device).to(torch.int64)\n",
        "            outputs = model(inputs)\n",
        "            in_preds.append(outputs)\n",
        "            in_label.append(labels)\n",
        "        in_preds = torch.cat(in_preds)\n",
        "        in_label = torch.cat(in_label)\n",
        "\n",
        "    return accuracy_score(\n",
        "        np.array(torch.argmax(in_preds, axis=1).cpu()), np.array(in_label.cpu())\n",
        "    )"
      ],
      "metadata": {
        "id": "HQ919GCLQAWl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CIFAR10 dataset\n",
        "def prepare_dataloader(num_clients, myid, train=True, path=\".\"):\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.4914, 0.4821, 0.4465], std=[0.2470, 0.2435, 0.2616])])\n",
        "    \n",
        "    if train:\n",
        "        dataset = datasets.CIFAR10(path, train=True, download=True, transform=transform)\n",
        "        idxs = list(range(len(dataset.data)))\n",
        "        random.shuffle(idxs)\n",
        "        idx = np.array_split(idxs, num_clients, 0)[myid - 1]\n",
        "        dataset.data = dataset.data[idx]\n",
        "        dataset.targets = np.array(dataset.targets)\n",
        "        dataset.targets = dataset.targets[idx]\n",
        "        train_loader = torch.utils.data.DataLoader(\n",
        "            NumpyDataset(\n",
        "                x=dataset.data,\n",
        "                y=dataset.targets,\n",
        "                transform=transform,\n",
        "                return_idx=True,\n",
        "            ),\n",
        "            batch_size=batch_size,\n",
        "        )\n",
        "        return train_loader\n",
        "    else:\n",
        "        dataset = datasets.CIFAR10(path, train=False, download=True, transform=transform)\n",
        "        test_loader = torch.utils.data.DataLoader(\n",
        "            NumpyDataset(\n",
        "                x=dataset.data,\n",
        "                y=dataset.targets,\n",
        "                transform=transform,\n",
        "                return_idx=True,\n",
        "            ),\n",
        "            batch_size=batch_size,\n",
        "        )\n",
        "        return test_loader\n",
        "\n",
        "dataloaders = [prepare_dataloader(num_clients + 1, c) for c in range(num_clients + 1)]\n",
        "public_dataloader = dataloaders[0]\n",
        "private_dataloaders = dataloaders[1:]\n",
        "test_dataloader = prepare_dataloader(num_clients, -1, train=False)"
      ],
      "metadata": {
        "id": "eXNW0-mfNRFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#client\n",
        "class FedMDClient(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        model,\n",
        "        public_dataloader,\n",
        "        user_id=0,\n",
        "        output_dim=1,\n",
        "        batch_size=8,\n",
        "        base_loss_func=nn.CrossEntropyLoss(),\n",
        "        consensus_loss_func=nn.L1Loss(),\n",
        "        round_decimal=None,\n",
        "        device=\"cpu\",\n",
        "    ):\n",
        "        super(FedMDClient, self).__init__()\n",
        "        self.user_id = user_id\n",
        "        self.model = model\n",
        "        self.public_dataloader = public_dataloader\n",
        "        self.batch_size = batch_size\n",
        "        self.base_loss_func = base_loss_func\n",
        "        self.consensus_loss_func = consensus_loss_func\n",
        "        self.round_decimal = round_decimal\n",
        "        self.device = device\n",
        "\n",
        "        self.predicted_values_of_server = None\n",
        "\n",
        "        len_public_dataloader = len(self.public_dataloader.dataset)\n",
        "        self.logit2server = initialize_global_logit(\n",
        "            len_public_dataloader, output_dim, self.device\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def train(self):\n",
        "        self.model.train()\n",
        "\n",
        "    def eval(self):\n",
        "        self.model.eval()\n",
        "\n",
        "    def backward(self, loss):\n",
        "        loss.backward()\n",
        "\n",
        "    def upload(self):\n",
        "        for data in self.public_dataloader:\n",
        "            idx = data[0]\n",
        "            x = data[1]\n",
        "            x = x.to(self.device)\n",
        "            self.logit2server[idx, :] = self(x).detach()\n",
        "\n",
        "        if self.round_decimal is None:\n",
        "            return self.logit2server\n",
        "        else:\n",
        "            return torch_round_x_decimal(self.logit2server, self.round_decimal)\n",
        "\n",
        "    def download(self, predicted_values_of_server):\n",
        "        self.predicted_values_of_server = predicted_values_of_server\n",
        "\n",
        "    def local_train(self, local_epoch, criterion, trainloader, optimizer):\n",
        "        return default_local_train_for_client(\n",
        "            self, local_epoch, criterion, trainloader, optimizer\n",
        "        )\n",
        "\n",
        "    def approach_consensus(self, consensus_optimizer):\n",
        "        running_loss = 0\n",
        "\n",
        "        for data in self.public_dataloader:\n",
        "            idx = data[0]\n",
        "            x = data[1].to(self.device)\n",
        "            y_consensus = self.predicted_values_of_server[idx, :].to(self.device)\n",
        "            consensus_optimizer.zero_grad()\n",
        "            y_pred = self(x)\n",
        "            loss = self.consensus_loss_func(y_pred, y_consensus)\n",
        "            loss.backward()\n",
        "            consensus_optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        return running_loss"
      ],
      "metadata": {
        "id": "HuxyrPcEjyK9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sever\n",
        "class FedMDServer(torch.nn.Module):\n",
        "    def __init__( self, clients, server_model=None, server_id=0, device=\"cpu\" ):\n",
        "        super(FedMDServer, self).__init__()\n",
        "        self.clients = clients\n",
        "        self.server_id = server_id\n",
        "        self.server_model = server_model\n",
        "        self.num_clients = len(clients)\n",
        "        self.device = device\n",
        "        self.uploaded_logits = []\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.server_model is not None:\n",
        "            return self.server_model(x)\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def train(self):\n",
        "        self.server_model.train()\n",
        "\n",
        "    def eval(self):\n",
        "        self.server_model.eval()\n",
        "    \n",
        "    def action(self):\n",
        "        self.receive()\n",
        "        self.update()\n",
        "        self.distribute()\n",
        "\n",
        "    def receive(self):\n",
        "        self.uploaded_logits = [client.upload() for client in self.clients]\n",
        "\n",
        "    def update(self):\n",
        "        len_clients = len(self.clients)\n",
        "        self.consensus = self.uploaded_logits[0] / len_clients\n",
        "        for logit in self.uploaded_logits[1:]:\n",
        "            self.consensus += logit / len_clients\n",
        "\n",
        "    def distribute(self):\n",
        "        \"\"\"Distribute the logits of public dataset to each client.\"\"\"\n",
        "        for client in self.clients:\n",
        "            client.download(self.consensus)\n"
      ],
      "metadata": {
        "id": "q6KXFXrLqTu7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#FedMD\n",
        "class FedMD(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        server,\n",
        "        clients,\n",
        "        public_dataloader,\n",
        "        local_dataloaders,\n",
        "        criterion,\n",
        "        client_optimizers,\n",
        "        test_dataloader=None,\n",
        "        server_optimizer=None,\n",
        "        num_communication=1,\n",
        "        device=\"cpu\",\n",
        "        consensus_epoch=1,\n",
        "        revisit_epoch=1,\n",
        "        transfer_epoch_public=1,\n",
        "        transfer_epoch_private=1,\n",
        "        server_training_epoch=1,\n",
        "        custom_action=lambda x: x,\n",
        "    ):\n",
        "        super(FedMD, self).__init__()\n",
        "        self.server = server\n",
        "        self.clients = clients\n",
        "        self.public_dataloader = public_dataloader\n",
        "        self.local_dataloaders = local_dataloaders\n",
        "        self.test_dataloader = test_dataloader\n",
        "        self.criterion = criterion\n",
        "        self.num_communication = num_communication\n",
        "        self.device = device\n",
        "        self.client_optimizers = client_optimizers\n",
        "        self.server_optimizer = server_optimizer\n",
        "        self.consensus_epoch = consensus_epoch\n",
        "        self.revisit_epoch = revisit_epoch\n",
        "        self.transfer_epoch_public = transfer_epoch_public\n",
        "        self.transfer_epoch_private = transfer_epoch_private\n",
        "        self.server_training_epoch = server_training_epoch\n",
        "        self.custom_action = custom_action\n",
        "        self.epoch = 0\n",
        "        self.client_num = len(clients)\n",
        "\n",
        "\n",
        "    def train_client(self, epoch=1, public=True):\n",
        "        \"\"\"\n",
        "        Train local models with the local datasets or the public dataset.\n",
        "        input: public (bool, optional): Train with the public dataset or the local datasets.\n",
        "        output: List[float]: a list of average loss of each clients.\n",
        "        \"\"\"\n",
        "        loss_on_local_dataset = []\n",
        "        for client_idx in range(self.client_num):\n",
        "            if public:\n",
        "                trainloader = self.public_dataloader\n",
        "            else:\n",
        "                trainloader = self.local_dataloaders[client_idx]\n",
        "\n",
        "            running_loss = self.clients[client_idx].local_train(\n",
        "                epoch, self.criterion, trainloader, self.client_optimizers[client_idx]\n",
        "            )\n",
        "\n",
        "            loss_on_local_dataset.append(copy.deepcopy(running_loss / len(trainloader)))\n",
        "\n",
        "        return loss_on_local_dataset\n",
        "\n",
        "\n",
        "    def train_server(self):\n",
        "        if self.server_optimizer is None:\n",
        "            return 0.0\n",
        "\n",
        "        running_loss = 0.0\n",
        "        for data in self.public_dataloader:\n",
        "            _, x, y = data\n",
        "            x = x.to(self.device)\n",
        "            y = y.to(self.device).to(torch.int64)\n",
        "\n",
        "            self.server_optimizer.zero_grad()\n",
        "            loss = self.criterion(self.server(x), y)\n",
        "            loss.backward()\n",
        "            self.server_optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        running_loss /= len(self.public_dataloader)\n",
        "\n",
        "        return running_loss\n",
        "\n",
        "\n",
        "    def score(self, dataloader, only_local=False):\n",
        "        \"\"\"\n",
        "        Returns the performance on the given dataset.\n",
        "        input: dataloader (torch.utils.data.DataLoader): a dataloader\n",
        "               only_local (bool): show only the local results\n",
        "        output: Dict[str, int]: performance of global model and local models\n",
        "        \"\"\"\n",
        "\n",
        "        clients_score = [\n",
        "            accuracy_torch_dataloader(client, dataloader, device=self.device)\n",
        "            for client in self.clients\n",
        "        ]\n",
        "\n",
        "        if only_local:\n",
        "            return {\"clients_score\": clients_score}\n",
        "        else:\n",
        "            server_score = accuracy_torch_dataloader(\n",
        "                self.server, dataloader, device=self.device\n",
        "            )\n",
        "            return {\"server_score\": server_score, \"clients_score\": clients_score}\n",
        "\n",
        "\n",
        "    def local_score(self):\n",
        "        \"\"\"\n",
        "        Returns the local performance of each clients.\n",
        "        output: Dict[str, int]: performance of global model and local models\n",
        "        \"\"\"\n",
        "        local_score_list = []\n",
        "        for client, local_dataloader in zip(self.clients, self.local_dataloaders):\n",
        "            temp_score = accuracy_torch_dataloader(\n",
        "                client, local_dataloader, device=self.device\n",
        "            )\n",
        "            local_score_list.append(temp_score)\n",
        "\n",
        "        return {\"clients_score\": local_score_list}\n",
        "\n",
        "\n",
        "    def transfer_phase(self, logging):\n",
        "        # Transfer\n",
        "        for i in range(1, self.transfer_epoch_public + 1):\n",
        "            loss_public = self.train_client(public=True)\n",
        "            #print(f\"epoch {i} (public - pretrain): {loss_public}\")\n",
        "            logging[\"loss_client_public_dataset_transfer\"].append(loss_public)\n",
        "        \n",
        "        if self.public_dataloader is not None:\n",
        "            acc_pub = self.score(\n",
        "                self.public_dataloader, self.server_optimizer is None\n",
        "            )\n",
        "            #print(\"acc on public dataset: \", acc_pub)\n",
        "            logging[\"acc_pub\"].append(copy.deepcopy(acc_pub))\n",
        "\n",
        "        for i in range(1, self.transfer_epoch_private + 1):\n",
        "            loss_local = self.train_client(public=False)\n",
        "            #print(f\"epoch {i} (local - pretrain): {loss_local}\")\n",
        "            logging[\"loss_client_local_dataset_transfer\"].append(loss_local)\n",
        "        \n",
        "        if self.public_dataloader is not None:\n",
        "            acc_pub = self.score(\n",
        "                self.public_dataloader, self.server_optimizer is None\n",
        "            )\n",
        "            #print(\"acc on public dataset: \", acc_pub)\n",
        "            logging[\"acc_pub\"].append(copy.deepcopy(acc_pub))\n",
        "\n",
        "        return logging\n",
        "\n",
        "    def digest_phase(self, i, logging):\n",
        "        temp_consensus_loss = []\n",
        "        for j, client in enumerate(self.clients):\n",
        "            for _ in range(self.consensus_epoch):\n",
        "                consensus_loss = client.approach_consensus(self.client_optimizers[j])\n",
        "            #print(f\"epoch {i}, client {j}: {consensus_loss}\")\n",
        "            temp_consensus_loss.append(consensus_loss)\n",
        "        logging[\"loss_client_consensus\"].append(temp_consensus_loss)\n",
        "        return logging\n",
        "\n",
        "    def revisit_phase(self, logging):\n",
        "        for _ in range(self.revisit_epoch):\n",
        "            loss_local_revisit = self.train_client(public=False)\n",
        "        logging[\"loss_client_revisit\"].append(loss_local_revisit)\n",
        "        return logging\n",
        "\n",
        "    def server_side_training(self, logging):\n",
        "        # Train a server-side model if it exists\n",
        "        for _ in range(self.server_training_epoch):\n",
        "            loss_server_public = self.train_server()\n",
        "        logging[\"loss_server_public_dataset\"].append(loss_server_public)\n",
        "        return logging\n",
        "\n",
        "    def evaluation(self, i, logging):\n",
        "        acc_on_local_dataset = self.local_score()\n",
        "        #print(f\"epoch={i} acc on local datasets: \", acc_on_local_dataset)\n",
        "        logging[\"acc_local\"].append(acc_on_local_dataset)\n",
        "        acc_pub = self.score(self.public_dataloader, self.server_optimizer is None)\n",
        "        #print(f\"epoch={i} acc on public dataset: \", acc_pub)\n",
        "        logging[\"acc_pub\"].append(copy.deepcopy(acc_pub))\n",
        "        # evaluation\n",
        "        if self.test_dataloader is not None:\n",
        "            acc_test = self.score(\n",
        "                self.test_dataloader, self.server_optimizer is None\n",
        "            )\n",
        "            print(f\"epoch={i} acc on test dataset: \", acc_test)\n",
        "            logging[\"acc_test\"].append(copy.deepcopy(acc_test))\n",
        "\n",
        "        return logging\n",
        "\n",
        "    def run(self):\n",
        "        logging = {\n",
        "            \"loss_client_local_dataset_transfer\": [],\n",
        "            \"loss_client_public_dataset_transfer\": [],\n",
        "            \"loss_client_consensus\": [],\n",
        "            \"loss_client_revisit\": [],\n",
        "            \"loss_server_public_dataset\": [],\n",
        "            \"acc_local\": [],\n",
        "            \"acc_pub\": [],\n",
        "            \"acc_test\": [],\n",
        "        }\n",
        "\n",
        "        logging = self.transfer_phase(logging)\n",
        "\n",
        "        for i in range(1, self.num_communication + 1):\n",
        "\n",
        "            self.epoch = i\n",
        "            self.server.action()\n",
        "            logging = self.digest_phase(i, logging)\n",
        "            logging = self.revisit_phase(logging)\n",
        "            logging = self.server_side_training(logging)\n",
        "            logging = self.evaluation(i, logging)\n",
        "\n",
        "            self.custom_action(self)\n",
        "\n",
        "        return logging"
      ],
      "metadata": {
        "id": "SlIdvPNyslGg"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN models\n",
        "class CNN2L(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN2L, self).__init__()\n",
        "        self.CNN1 = nn.Sequential(nn.Conv2d(in_channels=3,\n",
        "                                            kernel_size=3, out_channels=128,padding=1),\n",
        "                                  nn.BatchNorm2d(128),\n",
        "                                  nn.ReLU(),\n",
        "                                  nn.Dropout2d(0.2),\n",
        "                                  nn.AvgPool2d(kernel_size=2, stride=1))\n",
        "        self.CNN2 = nn.Sequential(nn.Conv2d(in_channels=128,stride=2,\n",
        "                                            kernel_size=3, out_channels=256),\n",
        "                                  nn.BatchNorm2d(256),\n",
        "                                  nn.ReLU(),\n",
        "                                  nn.Dropout2d(0.2))\n",
        "        self.FC1 = nn.Linear(57600,10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.CNN1(x)\n",
        "        x = self.CNN2(x)\n",
        "        # print(x.shape)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        # print(x.shape)\n",
        "        x = self.FC1(x)\n",
        "        return F.softmax(x,dim=1)\n",
        "\n",
        "class CNN3L(nn.Module):\n",
        "    def __init__(self, num_classes, n1, n2, n3, dropout_rate):\n",
        "        super(CNN3L, self).__init__()\n",
        "        self.CNN1 = nn.Sequential(nn.Conv2d(in_channels=3, #3 channels for CIFAR\n",
        "                                            kernel_size=3, out_channels=n1,padding=1),\n",
        "                                  nn.BatchNorm2d(n1),\n",
        "                                  nn.ReLU(),\n",
        "                                  nn.Dropout2d(dropout_rate),\n",
        "                                  nn.AvgPool2d(kernel_size=2, stride=1))\n",
        "        self.CNN2 = nn.Sequential(nn.Conv2d(in_channels=n1,stride=2,\n",
        "                                            kernel_size=2, out_channels=n2),\n",
        "                                  nn.BatchNorm2d(n2),\n",
        "                                  nn.ReLU(),\n",
        "                                  nn.Dropout2d(dropout_rate),\n",
        "                                  nn.AvgPool2d(kernel_size=2))\n",
        "        self.CNN3 = nn.Sequential(nn.Conv2d(in_channels=n2,stride=2,\n",
        "                                            kernel_size=3, out_channels=n3),\n",
        "                                  nn.BatchNorm2d(n3),\n",
        "                                  nn.ReLU(),\n",
        "                                  nn.Dropout2d(dropout_rate))\n",
        "        self.FC1 = nn.Linear(n3 * 9, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.CNN1(x)\n",
        "        # print(x.shape)\n",
        "        x = self.CNN2(x)\n",
        "        # print(x.shape)\n",
        "        x = self.CNN3(x)\n",
        "        # print(x.shape)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        # print(x.shape)\n",
        "        x = self.FC1(x)\n",
        "        return F.softmax(x,dim=1)"
      ],
      "metadata": {
        "id": "26YzcPsovGe-"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ResNet\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
        "        self.gn1 = nn.GroupNorm(2,out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
        "        self.gn2 = nn.GroupNorm(2,out_channels)\n",
        "        self.downsample = downsample\n",
        "        \n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        if self.downsample:\n",
        "            residual = self.downsample(x)\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "    \n",
        "class ResNet20(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ResNet20, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.gn1 = nn.GroupNorm(2,16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self.make_layer(16, 16, 3)\n",
        "        self.layer2 = self.make_layer(16, 32, 3, stride=2)\n",
        "        self.layer3 = self.make_layer(32, 64, 3, stride=2)\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(64, num_classes)\n",
        "        \n",
        "    def make_layer(self, in_channels, out_channels, block_num, stride=1):\n",
        "        downsample = None\n",
        "        if (stride != 1) or (in_channels != out_channels):\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1),\n",
        "                nn.GroupNorm(2,out_channels))\n",
        "        layers = []\n",
        "        layers.append(ResidualBlock(in_channels, out_channels, stride, downsample))\n",
        "        for i in range(1, block_num):\n",
        "            layers.append(ResidualBlock(out_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.avg_pool(out)\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "8y2YHJTD1NKI"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = [CNN2L(), \n",
        "          CNN3L(10, 128, 128, 192, 0.2), \n",
        "          CNN3L(10,  64,  64,  64, 0.2), \n",
        "          CNN3L(10, 128,  64,  64, 0.3), \n",
        "          CNN3L(10,  64,  64, 128, 0.4),\n",
        "          CNN3L(10,  64, 128, 256, 0.2), \n",
        "          CNN3L(10,  64, 128, 192, 0.2), \n",
        "          CNN3L(10, 128, 192, 256, 0.2), \n",
        "          CNN3L(10, 128, 128, 128, 0.3),\n",
        "          CNN3L(10, 128, 128, 128, 0.3)]"
      ],
      "metadata": {
        "id": "2oSw7hPxyY-Y"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clients = [\n",
        "    FedMDClient(models[c].to(device), public_dataloader, output_dim=10, user_id=c, device=device)\n",
        "    for c in range(num_clients)\n",
        "]\n",
        "local_optimizers = [optim.SGD(client.parameters(), lr=lr) for client in clients]\n",
        "\n",
        "server = FedMDServer(clients, ResNet20().to(device), device=device)\n",
        "\n",
        "api = FedMD(\n",
        "    server,\n",
        "    clients,\n",
        "    public_dataloader,\n",
        "    private_dataloaders,\n",
        "    F.nll_loss,\n",
        "    local_optimizers,\n",
        "    test_dataloader,\n",
        "    num_communication=32,\n",
        "    device=device\n",
        ")\n",
        "log = api.run()"
      ],
      "metadata": {
        "id": "odxzM8TWy9zR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc_test = log[\"acc_test\"]\n",
        "x = list(range(32))\n",
        "colors = ['red','darkorange','green','blue','purple','brown','magenta','grey','gold','cyan']\n",
        "legends = []\n",
        "\n",
        "for i in range(10):\n",
        "  y = []\n",
        "  for j in range(32):\n",
        "    y.append(acc_test[j][\"clients_score\"][i])\n",
        "  plt.plot(x, y, color = colors[i], marker='.')\n",
        "  legends.append(\"model \"+str(i))\n",
        "\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"test accuracy\")\n",
        "plt.legend(legends, loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9kbr7HKLbXUZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}